# -*- coding: utf-8 -*-
"""Karavi-Alireza-PatternRecognition-RemoteWorkOnMentalHealth-14030814-k-means.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mVtMrgSC6nVtYtZxcplzHYM-rdL0tVCB
"""

# نصب کتابخانه‌های لازم
!pip install matplotlib seaborn

# مرحله 1: لود کردن کتابخانه‌ها
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# مرحله 2: بارگذاری دیتاست
# اگر دیتاست در Google Drive است، ابتدا Google Drive را متصل کنید
from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/SourceKaravi/NTK.Education.Practice/
!git pull
# %cd /content/gdrive/MyDrive/SourceKaravi/NTK.Education.Practice/PatternRecognition/RemoteWorkOnMentalHealth/

# بارگذاری دیتاست (توجه: آدرس فایل خود را وارد کنید)
df = pd.read_csv('/content/gdrive/MyDrive/SourceKaravi/NTK.Education.Practice/PatternRecognition/RemoteWorkOnMentalHealth/Impact_of_Remote_Work_on_Mental_Health.csv')

# مرحله 3: بررسی فیلدهای دیتاست
print(df.head())  # نمایش 5 ردیف اول دیتاست

print(df.info())  # اطلاعات کلی درباره دیتاست

df.isnull().sum()

# تبدیل ستون به نوع int
#df['Work_Location'] = df['Work_Location'].map({'Onsite':1, 'Remote': 2,'Hybrid': 3 })
#df['Work_Location'] = df['Work_Location'].astype(int)
# تبدیل ستون به نوع int
#df['Stress_Level'] = df['Stress_Level'].map({'Low': 1, 'Medium': 2, 'High': 3})
#df['Stress_Level'] = df['Stress_Level'].astype(int)

df  = df.dropna()

df

df.shape

df.columns

df['Age']

plt.figure(figsize=(10,6))
plt.hist(df['Age'],bins=range(1,101,10),edgecolor='black',color='green')
plt.title('Age Distribution')
plt.xlabel('Age Range')
plt.ylabel('Count of Age')
plt.show()

df['Age'].describe()

df['Gender'].unique()

df['Gender'].value_counts().plot(kind='bar', color='pink', edgecolor='black')
plt.title('Gender Distribution')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.show()

df['Industry'].value_counts().plot(kind='bar', color='lightgreen', edgecolor='black')
plt.title('Industry Distribution')
plt.xlabel('Industry')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

plt.hist(df['Years_of_Experience'], bins=10, color='purple', edgecolor='black')
plt.title('Years of Experience Distribution')
plt.xlabel('Years of Experience')
plt.ylabel('Frequency')
plt.show()

df['Work_Location'].value_counts().plot(kind='bar', color='cyan', edgecolor='black')
plt.title('Work Location Distribution')
plt.xlabel('Work Location')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

plt.hist(df['Hours_Worked_Per_Week'], bins=10, color='orange', edgecolor='black')
plt.title('Hours Worked Per Week Distribution')
plt.xlabel('Hours Worked Per Week')
plt.ylabel('Frequency')
plt.show()

plt.hist(df['Number_of_Virtual_Meetings'], bins=10, color='yellow', edgecolor='black')
plt.title('Number of Virtual Meetings')
plt.xlabel('Virtual Meetings per Week')
plt.ylabel('Frequency')
plt.show()

df['Work_Life_Balance_Rating'].value_counts().plot(kind='bar', color='lightblue', edgecolor='black')
plt.title('Work-Life Balance Rating')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

df['Stress_Level'].value_counts().plot(kind='bar', color='red', edgecolor='black')
plt.title('Stress Level Distribution')
plt.xlabel('Stress Level')
plt.ylabel('Count')
plt.show()

df['Mental_Health_Condition'].value_counts().plot(kind='bar', color='purple', edgecolor='black')
plt.title('Mental Health Condition')
plt.xlabel('Mental Health Condition')
plt.ylabel('Count')
plt.show()

df['Access_to_Mental_Health_Resources'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['green', 'lightcoral'])
plt.title('Access to Mental Health Resources')
plt.show()

plt.hist(df['Productivity_Change'], bins=10, color='magenta', edgecolor='black')
plt.title('Productivity Change')
plt.xlabel('Productivity Change')
plt.ylabel('Frequency')
plt.show()

df['Social_Isolation_Rating'].value_counts().plot(kind='bar', color='blue', edgecolor='black')
plt.title('Social Isolation Rating')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()

df['Satisfaction_with_Remote_Work'].value_counts().plot(kind='bar', color='orange', edgecolor='black')
plt.title('Satisfaction with Remote Work')
plt.xlabel('Satisfaction Level')
plt.ylabel('Count')
plt.show()

df['Company_Support_for_Remote_Work'].value_counts().plot(kind='bar', color='green', edgecolor='black')
plt.title('Company Support for Remote Work')
plt.xlabel('Support Level')
plt.ylabel('Count')
plt.show()

plt.hist(df['Physical_Activity'], bins=10, color='lightgreen', edgecolor='black')
plt.title('Physical Activity')
plt.xlabel('Physical Activity Level')
plt.ylabel('Frequency')
plt.show()

df['Region'].value_counts().plot(kind='bar', color='lightblue', edgecolor='black')
plt.title('Region Distribution')
plt.xlabel('Region')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

df.info()

# Drop Employee_ID
df = df.drop('Employee_ID', axis=1)

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
le = LabelEncoder()

# Apply label encoding to the 'Physical_Activity' column
df['Physical_Activity'] = le.fit_transform(df['Physical_Activity'])

df.info()

from sklearn.preprocessing import StandardScaler

# List of numerical columns
numerical_cols = df.select_dtypes(include=['int64']).columns

# Initialize StandardScaler
scaler = StandardScaler()

# Apply scaling to numerical columns
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

print(df.head())
print(df.info())

print(df['Mental_Health_Condition'].unique())

print(df['Mental_Health_Condition'].isnull().sum())

df = df.dropna(subset=['Mental_Health_Condition'])

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay

categorical_columns = ['Gender', 'Job_Role', 'Industry', 'Work_Location',
                       'Stress_Level', 'Mental_Health_Condition',
                       'Access_to_Mental_Health_Resources',
                       'Productivity_Change', 'Satisfaction_with_Remote_Work',
                       'Sleep_Quality', 'Region']

df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Separate features and targets
X = df_encoded.drop(['Stress_Level_Medium', 'Productivity_Change_Increase'], axis=1)
y = df_encoded[['Stress_Level_Medium', 'Productivity_Change_Increase']]  # Adjust based on your needs

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
multi_target_model = MultiOutputClassifier(rf_model, n_jobs=-1)

multi_target_model.fit(X_train, y_train)

y_pred = multi_target_model.predict(X_test)

print("Classification Report for Stress Level:")
print(classification_report(y_test['Stress_Level_Medium'], y_pred[:, 0], target_names=['Low_Stress', 'High_Stress']))

print("\nClassification Report for Productivity Change:")
print(classification_report(y_test['Productivity_Change_Increase'], y_pred[:, 1], target_names=['Decrease_Prod', 'Increase_Prod']))

fig, ax = plt.subplots(1, 2, figsize=(14, 5))

ConfusionMatrixDisplay.from_predictions(
    y_test['Stress_Level_Medium'],
    y_pred[:, 0],
    display_labels=['Low_Stress', 'High_Stress'],
    cmap='Blues',
    ax=ax[0]
)
ax[0].set_title("Confusion Matrix for Stress Level")


# Plot confusion matrix for Productivity Change
ConfusionMatrixDisplay.from_predictions(
    y_test['Productivity_Change_Increase'],
    y_pred[:, 1],
    display_labels=['Decrease_Prod', 'Increase_Prod'],
    cmap='Greens',
    ax=ax[1]
)
ax[1].set_title("Confusion Matrix for Productivity Change")

plt.tight_layout()
plt.show()



from sklearn.cluster import KMeans

# تعداد خوشه‌ها
n_clusters = 3

# اجرای الگوریتم K-Means
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
kmeans.fit(X)
y_kmeans = kmeans.predict(X)

from sklearn.metrics import silhouette_score

# محاسبه نمره سیلوئت
silhouette_avg = silhouette_score(X, y_kmeans)
print(f'Silhouette Score: {silhouette_avg}')

from sklearn.metrics import mean_squared_error
# محاسبه MSE
mse_list = []
for i in range(n_clusters):
    cluster_points = X[y_kmeans == i]
    cluster_center = kmeans.cluster_centers_[i]
    mse = mean_squared_error(cluster_points, [cluster_center] * len(cluster_points))
    mse_list.append(mse)

print("Mean Squared Error for each cluster:")
for i, mse in enumerate(mse_list):
    print(f"Cluster {i}: MSE = {mse}")

X

# نمایش نتایج
plt.figure(figsize=(10, 6))
#plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis', marker='o', edgecolor='k', s=100)
plt.scatter(X[:, 0], X.[:, 1], c=y_kmeans, cmap='viridis', marker='o', edgecolor='k', s=100)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', s=300, alpha=0.75, marker='X')
plt.title('K-Means Clustering on  Dataset')
plt.xlabel('y')
plt.ylabel('x')
plt.show()

# مرحله 6: ارزیابی مدل
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')